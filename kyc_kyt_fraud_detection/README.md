# ğŸ¦ KYC/KYT Loan Default Prediction

A production-ready machine learning system for predicting loan defaults using **KYC (Know Your Customer)** and **KYT (Know Your Transaction)** approaches, with hyperparameter optimization via **Optuna**.

---

## ğŸ“Š Project Overview

This system predicts loan defaults by combining:
- **KYC Features**: Loan characteristics (amount, duration, payments)
- **KYT Features**: Transaction behavior patterns (frequency, volatility, balance stability)

**Dataset**: Czech Banking Dataset (PKDD'99)
- **682 loans** (6.6% default rate)
- **1,056,320 transactions** from 4,500 accounts

---

## ğŸ¯ Performance

| Model | Precision | Recall | F1 | ROC-AUC | Avg Precision |
|-------|-----------|--------|-----|---------|---------------|
| **Random Forest (Tuned)** | 72.7% | **88.9%** | 80.0% | **99.1%** | **91.1%** |
| XGBoost (Tuned) | 72.7% | 88.9% | 80.0% | 99.1% | 90.0% |
| Autoencoder | 35.3% | 66.7% | 46.2% | 93.5% | 47.2% |

**Key Achievement**: 14.3% improvement in Average Precision after Optuna tuning (76.8% â†’ 91.1%)

---

## ğŸ—‚ï¸ Project Structure

```
kyc_kyt_fraud_detection/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # Centralized configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # loan.csv, trans.csv
â”‚   â””â”€â”€ processed/               # Processed features
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py            # Czech Bank data loader
â”‚   â”‚   â”œâ”€â”€ aggregator.py        # Transaction aggregation
â”‚   â”‚   â””â”€â”€ validator.py         # Data quality checks
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ kyc_features.py      # Customer-level features
â”‚   â”‚   â”œâ”€â”€ kyt_features.py      # Transaction behavior features
â”‚   â”‚   â””â”€â”€ engineering.py       # Feature engineering pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py              # Base model class
â”‚   â”‚   â”œâ”€â”€ supervised.py        # XGBoost, Random Forest
â”‚   â”‚   â”œâ”€â”€ unsupervised.py      # Autoencoder anomaly detection
â”‚   â”‚   â””â”€â”€ optimizer.py         # Optuna hyperparameter tuning
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚       â””â”€â”€ statistical_tests.py # Cohen's d, KS test
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py                 # Training pipeline
â”‚
â”œâ”€â”€ models/                      # Saved models
â”œâ”€â”€ reports/                     # Evaluation reports
â””â”€â”€ notebooks/                   # Exploratory analysis
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
cd kyc_kyt_fraud_detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or install as package
pip install -e .
```

### Prepare Data

Place the Czech Bank dataset files in `data/raw/`:
- `loan.csv`
- `trans.csv`

### Train Models

```bash
# Train all models with pre-tuned parameters (fast)
python scripts/train.py

# Train specific model
python scripts/train.py --model random_forest

# Run Optuna optimization (slow but better results)
python scripts/train.py --model random_forest --optimize --n-trials 50

# Full optimization on all models
python scripts/train.py --model all --optimize --n-trials 50
```

---

## ğŸ“ˆ Key Features

### 1. **KYC Features** (Loan Characteristics)
```python
- payment_to_amount          # Monthly payment burden
- amount_per_month           # Loan size per month
- overpayment_ratio          # Total payment / original amount
- implied_interest_rate      # Effective interest rate
- loan_size categories       # Short/medium/long-term
```

### 2. **KYT Features** (Transaction Behavior)
```python
- amount_cv                  # Transaction amount volatility
- balance_stability          # Inverse of balance CV
- had_negative_balance       # Risk flag
- balance_range              # Min-max spread
- tx_type_diversity          # Transaction type entropy
```

### 3. **Interaction Features** (KYC Ã— KYT)
```python
- loan_to_balance            # Loan size vs average balance
- payment_to_avg_transaction # Payment burden vs spending
- risk_flag_count            # Combined risk indicators
```

---

## ğŸ”¬ Model Details

### Random Forest (Best Model)

**Optuna-Tuned Hyperparameters:**
```python
{
    'n_estimators': 173,
    'max_depth': 5,
    'min_samples_split': 9,
    'min_samples_leaf': 5,
    'max_features': None,
    'class_weight': 'balanced'
}
```

**Why it's best:**
- Highest Average Precision (91.1%)
- Excellent recall (88.9% of defaults detected)
- More interpretable than XGBoost
- Less prone to overfitting on small dataset

### XGBoost (Alternative)

**Optuna-Tuned Hyperparameters:**
```python
{
    'n_estimators': 358,
    'max_depth': 6,
    'learning_rate': 0.038805,
    'scale_pos_weight': 25.217325,
    # ... (see config/settings.py for full params)
}
```

---

## ğŸ“Š Feature Discrimination Analysis

Top features by Cohen's d (effect size):

| Feature | Cohen's d | Effect | Interpretation |
|---------|-----------|--------|----------------|
| `amount_min` | 1.69 | **Large** | Minimum transaction amount differs significantly |
| `balance_min` | 1.34 | **Large** | Defaults have negative balances (-4.6k avg) |
| `amount` (loan) | 0.86 | **Large** | Defaults borrow 72% more |
| `balance_median` | 0.82 | **Large** | Defaults have 26% lower median balance |
| `balance_mean` | 0.76 | **Medium** | 23% lower average balance |

---

## ğŸ› ï¸ Configuration

Edit `config/settings.py` to customize:

```python
# Data paths
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"

# Model selection
DEFAULT_MODEL = "random_forest"  # or "xgboost"

# Optuna settings
N_TRIALS = 50
CV_FOLDS = 5
METRIC = "average_precision"

# Risk thresholds
CRITICAL_RISK_THRESHOLD = 0.8
HIGH_RISK_THRESHOLD = 0.6
MEDIUM_RISK_THRESHOLD = 0.3
```

---

## ğŸ“š Usage Examples

### Python API

```python
from pathlib import Path
from src.data.loader import CzechBankDataLoader
from src.data.aggregator import TransactionAggregator
from src.features.engineering import FeatureEngineer
from src.models.supervised import RandomForestDefaultModel
import joblib

# Load data
loader = CzechBankDataLoader(Path("data/raw"))
loan_df, trans_df = loader.load_all()

# Aggregate transactions
aggregator = TransactionAggregator()
trans_agg = aggregator.aggregate(trans_df)

# Engineer features
engineer = FeatureEngineer()
df = engineer.engineer_features(loan_df, trans_agg)
X, y, features = engineer.prepare_modeling_data(df)

# Load trained model and scaler
model = RandomForestDefaultModel.load("models/random_forest_model.pkl")
scaler = joblib.load("models/scaler.pkl")

# Predict
X_scaled = scaler.transform(X)
predictions = model.predict(X_scaled)
probabilities = model.predict_proba(X_scaled)

# Get risk level
for prob in probabilities[:5]:
    risk = model.get_risk_level(prob)
    print(f"Probability: {prob:.2%}, Risk: {risk}")
```

### Hyperparameter Optimization

```python
from src.models.optimizer import OptunaOptimizer

# Initialize optimizer
optimizer = OptunaOptimizer(n_trials=50, metric='average_precision')

# Optimize Random Forest
best_params = optimizer.optimize_random_forest(X_train, y_train)

# Get optimization history
history = optimizer.get_optimization_history()
history.to_csv("rf_optimization_history.csv")
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test module
pytest tests/test_models.py
```

---

## ğŸ“ˆ Model Evaluation

The training script automatically generates:

1. **Model Comparison** (`reports/metrics/model_comparison.csv`)
2. **Feature Importance** (`reports/metrics/{model}_feature_importance.csv`)
3. **Optuna Study** (`reports/optuna_studies/{model}_optimization.csv`)
4. **Statistical Discrimination Analysis** (printed during training)

---

## ğŸ”„ Workflow

```
1. Load Data (loan.csv + trans.csv)
   â†“
2. Validate Quality
   â†“
3. Aggregate Transactions by Account
   â†“
4. Engineer Features (KYC + KYT)
   â†“
5. Statistical Analysis (Cohen's d, KS test)
   â†“
6. Train/Test Split + Scaling
   â†“
7. Train Models (with/without Optuna)
   â†“
8. Evaluate & Compare
   â†“
9. Save Best Model
```

---

## ğŸš§ Future Enhancements

- [ ] FastAPI REST API for real-time predictions
- [ ] SHAP values for model interpretability
- [ ] Time-series features (transaction trends)
- [ ] Ensemble stacking (RF + XGBoost)
- [ ] Docker containerization
- [ ] MLflow experiment tracking
- [ ] Production monitoring dashboard

---

## ğŸ“– Documentation

- **Model Card**: `docs/model_card.md`
- **Methodology**: `docs/methodology.md`
- **Implementation Log**: `../IMPLEMENTATION_LOG.md`

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Acknowledgments

- **Dataset**: Czech Banking Dataset (PKDD'99 Discovery Challenge)
- **Optuna**: For efficient Bayesian optimization
- **Scikit-learn, XGBoost**: Core ML libraries

---

## ğŸ“¬ Contact

For questions or issues, please open an issue on GitHub.

---

**Built with â¤ï¸ using Python, Optuna, and modern ML best practices**
